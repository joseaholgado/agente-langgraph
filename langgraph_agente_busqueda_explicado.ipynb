{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae7da91f",
   "metadata": {},
   "source": [
    "# Agente de B√∫squeda Inteligente\n",
    "Sistema que combina documentos locales en pdf, json y b√∫squeda web para respuestas precisas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bf858b",
   "metadata": {},
   "source": [
    "## 1. Configuraci√≥n Inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d154072",
   "metadata": {},
   "source": [
    "- Carga claves API desde `.env`\n",
    "- Inicializa el modelo de lenguaje GPT-3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c511a34d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Celda 1: Configuraci√≥n inicial\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "# Celda 1: Configuraci√≥n inicial\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import TypedDict\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "api_key_tavily = os.getenv(\"TAVILY_API_KEY\")\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", api_key=api_key, temperature=0, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0419dbb9",
   "metadata": {},
   "source": [
    "## 2. Motor de B√∫squeda en PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf87240",
   "metadata": {},
   "source": [
    "- Carga m√∫ltiples PDFs\n",
    "- Usa embeddings para b√∫squeda sem√°ntica\n",
    "- Provee respuestas con refencias a p√°ginas\n",
    "- Herramienta de PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf50910e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\6003465\\AppData\\Local\\Temp\\ipykernel_22232\\384757128.py:17: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "class BusquedaPDF:\n",
    "    def __init__(self, pdf_paths: list[str]):\n",
    "        docs = []\n",
    "        for path in pdf_paths:\n",
    "            if not os.path.exists(path):\n",
    "                raise FileNotFoundError(f\"Archivo no encontrado: {path}\")\n",
    "            loader = PyMuPDFLoader(path)\n",
    "            docs.extend(loader.load())\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "        frag = splitter.split_documents(docs)\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "        store = FAISS.from_documents(frag, embeddings)\n",
    "        self.qa = RetrievalQA.from_chain_type(\n",
    "            llm=ChatOpenAI(model=\"gpt-3.5-turbo\", api_key=api_key),\n",
    "            chain_type=\"stuff\",\n",
    "            retriever=store.as_retriever(search_kwargs={\"k\":3}),\n",
    "            return_source_documents=True\n",
    "        )\n",
    "    def run(self, query: str) -> str:\n",
    "        res = self.qa.invoke({\"query\":query})\n",
    "        answer = res.get(\"result\",\"\")\n",
    "        docs = res.get(\"source_documents\",[])\n",
    "        if docs:\n",
    "            fuentes = \"\\n\".join(f\"- {d.metadata.get('source','pdf')}\" for d in docs)\n",
    "            return f\"{answer}\\n\\nFuentes:\\n{fuentes}\"\n",
    "        return answer\n",
    "\n",
    "# Instanciar BusquedaPDF y herramienta\n",
    "from langchain.tools import Tool\n",
    "rutas_pdfs=[\"Investigaci√≥n de WindSurf.pdf\",\"nke-10k-2023.pdf\"]\n",
    "buscador_pdf=BusquedaPDF(rutas_pdfs)\n",
    "tool_pdf=Tool(\n",
    "    name=\"busqueda_pdf\",\n",
    "    func=buscador_pdf.run,\n",
    "    description=\"Busca en documentos PDF\",\n",
    "    metadata={\"category\":\"Documentos locales\",\"file_types\":[\".pdf\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0c3696",
   "metadata": {},
   "source": [
    "## 3. Motor de B√∫squeda en JSONs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b8c201",
   "metadata": {},
   "source": [
    "- Crea clase de busqueda JSONs\n",
    "- Crea el prompt como guia para el agente\n",
    "- Analiza contexto de la pregunta\n",
    "- Usa ejemplos para mejor precisi√≥n\n",
    "\n",
    "- Crea la herramienta JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9b9262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "class BusquedaJSON:\n",
    "    def __init__(self, json_paths: list[str]):\n",
    "        # Cargamos el AST completo\n",
    "        combined = {}\n",
    "        for path in json_paths:\n",
    "            if not os.path.exists(path):\n",
    "                raise FileNotFoundError(f\"Archivo no encontrado: {path}\")\n",
    "            with open(path, encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "            combined.update(data)\n",
    "        self.ast = combined\n",
    "\n",
    "    def run(self, query: str) -> str:\n",
    "        # Construimos prompt para el LLM que contiene el AST\n",
    "        ast_str = json.dumps(self.ast, indent=2, ensure_ascii=False)\n",
    "        prompt = [\n",
    "            SystemMessage(content=\"Eres un asistente experto en an√°lisis de AST de c√≥digo Python.\"),\n",
    "            HumanMessage(content=(\n",
    "                f\"Se te proporciona el siguiente AST en formato JSON de un archivo con definiciones de funciones, \"\n",
    "                f\"variables, comentarios y clases:\\n{ast_str}\\n\\n\"\n",
    "                f\"Indica primero la lista de funciones que contiene el AST (nombre y par√°metros), \"\n",
    "                f\"y luego explica brevemente el prop√≥sito de cada funci√≥n.\\n\"\n",
    "                f\"Consulta del usuario: {query}\"\n",
    "            ))\n",
    "        ]\n",
    "        respuesta = model(prompt).content\n",
    "        return respuesta\n",
    "\n",
    "# Instanciar BusquedaJSON y herramienta\n",
    "rutas_json=[\"ast_summary.json\"]\n",
    "buscador_json=BusquedaJSON(rutas_json)\n",
    "tool_json=Tool(\n",
    "    name=\"busqueda_json\",\n",
    "    func=buscador_json.run,\n",
    "    description=\"Analiza un AST JSON y explica sus funciones\",\n",
    "    metadata={\"category\":\"Documentos locales\",\"file_types\":[\".json\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c6be45",
   "metadata": {},
   "source": [
    "## 4. Herramienta de B√∫squeda Web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e167def",
   "metadata": {},
   "source": [
    "- Acceso a informaci√≥n actualizada\n",
    "- Resultados de alta relevancia\n",
    "- Filtrado de contenido irrelevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a0a900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "tavily=TavilySearch(max_results=5,topic=\"general\")\n",
    "def busqueda_internet(q:str)->str:\n",
    "    res=tavily.invoke({\"query\":q}).get(\"results\",[])\n",
    "    return \"\\n\\n\".join(r.get(\"content\",\"\") for r in res[:3]) or \"Sin resultados\"\n",
    "\n",
    "tool_web=Tool(\n",
    "    name=\"busqueda_internet\",\n",
    "    func=busqueda_internet,\n",
    "    description=\"Busca en internet\",\n",
    "    metadata={\"category\":\"B√∫squeda en vivo\",\"sources\":[\"Tavily\"]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddcab04",
   "metadata": {},
   "source": [
    "## 5. N√∫cleo de Decisi√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80b7e88",
   "metadata": {},
   "source": [
    "- Crea los nodo del Grafo\n",
    "- Previene errores de routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be959777",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from langchain.schema import SystemMessage as SysMsg, HumanMessage as HumMsg\n",
    "\n",
    "class AgentState(TypedDict): input:str; tool_used:str; output:str; next_step:str\n",
    "\n",
    "def decide_tool(state:AgentState)->AgentState:\n",
    "    text=state[\"input\"].lower()\n",
    "    if any(k in text for k in [\"windsurf\",\"pdf\"]): return {\"next_step\":\"usar_pdf\"}\n",
    "    if any(k in text for k in [\"json\",\"ast\",\"funcion\",\"variable\",\"comentario\",\"clase\"]): return {\"next_step\":\"usar_json\"}\n",
    "    return {\"next_step\":\"usar_web\"}\n",
    "\n",
    "def usar_pdf(state:AgentState)->AgentState:\n",
    "    out=buscador_pdf.run(state[\"input\"])\n",
    "    return {\"input\":state[\"input\"],\"tool_used\":\"busqueda_pdf\",\"output\":out}\n",
    "\n",
    "def usar_json(state:AgentState)->AgentState:\n",
    "    out=buscador_json.run(state[\"input\"])\n",
    "    return {\"input\":state[\"input\"],\"tool_used\":\"busqueda_json\",\"output\":out}\n",
    "\n",
    "def usar_web(state:AgentState)->AgentState:\n",
    "    out=busqueda_internet(state[\"input\"])\n",
    "    return {\"input\":state[\"input\"],\"tool_used\":\"busqueda_internet\",\"output\":out}\n",
    "\n",
    "# Montar y compilar grafo\n",
    "graph=StateGraph(AgentState)\n",
    "graph.add_node(\"decision\",decide_tool)\n",
    "graph.add_node(\"usar_pdf\",usar_pdf)\n",
    "graph.add_node(\"usar_json\",usar_json)\n",
    "graph.add_node(\"usar_web\",usar_web)\n",
    "graph.add_node(\"fin\",lambda s:s)\n",
    "\n",
    "graph.set_entry_point(\"decision\")\n",
    "graph.add_conditional_edges(\"decision\",lambda s:s[\"next_step\"],{\"usar_pdf\":\"usar_pdf\",\"usar_json\":\"usar_json\",\"usar_web\":\"usar_web\",\"fin\":\"fin\"})\n",
    "for n in [\"usar_pdf\",\"usar_json\",\"usar_web\"]: graph.add_edge(n,\"fin\")\n",
    "agent_executor=graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2699d5",
   "metadata": {},
   "source": [
    "# Celda 2 Modificada - Verificaci√≥n de PDFs\n",
    "class BusquedaPDF:\n",
    "    def __init__(self, pdf_paths):\n",
    "        try:\n",
    "            print(f\"üîç Cargando PDFs desde: {pdf_paths}\")\n",
    "            docs = []\n",
    "            for path in pdf_paths:\n",
    "                if not os.path.exists(path):\n",
    "                    raise FileNotFoundError(f\"Archivo no encontrado: {path}\")\n",
    "                loader = PyMuPDFLoader(path)\n",
    "                docs.extend(loader.load())\n",
    "                print(f\"‚úÖ {path} cargado correctamente ({len(docs)} documentos)\")\n",
    "\n",
    "            splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "            docs_fragmentados = splitter.split_documents(docs)\n",
    "            print(f\"üìö Total fragmentos creados: {len(docs_fragmentados)}\")\n",
    "\n",
    "            self.embeddings = HuggingFaceEmbeddings(\n",
    "                model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "                model_kwargs={'device': 'cpu'}  # A√±adir par√°metro para CPU\n",
    "            )\n",
    "\n",
    "            self.vectorstore = FAISS.from_documents(docs_fragmentados, self.embeddings)\n",
    "            print(\"ü¶Ñ Vectorstore FAISS creado exitosamente\")\n",
    "\n",
    "            self.qa_chain = RetrievalQA.from_chain_type(\n",
    "                llm=model,\n",
    "                chain_type=\"stuff\",\n",
    "                retriever=self.vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "                return_source_documents=True\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error cr√≠tico al cargar PDFs: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def run(self, query: str) -> str:\n",
    "        try:\n",
    "            print(f\"\\nüîé Buscando en PDFs: '{query}'\")\n",
    "            result = self.qa_chain.invoke({\"query\": query})\n",
    "\n",
    "            if not result[\"source_documents\"]:\n",
    "                return \"No se encontr√≥ informaci√≥n relevante en los documentos.\"\n",
    "\n",
    "            sources = \"\\n\".join(\n",
    "                f\"- {doc.metadata['source']} (p√°gina {doc.metadata.get('page', 'N/A')})\"\n",
    "                for doc in result[\"source_documents\"]\n",
    "            )\n",
    "\n",
    "            return f\"{result['result']}\\n\\nFuentes:\\n{sources}\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error en b√∫squeda PDF: {str(e)}\")\n",
    "            return \"Error al consultar los documentos.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf4233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot de LangGraph - escriba 'salir' para terminar.\n",
      "\n",
      "Respuesta: Sin resultados\n",
      "Herramienta usada: busqueda_internet\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\6003465\\AppData\\Local\\Temp\\ipykernel_22232\\1204031144.py:29: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  respuesta = model(prompt).content\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Respuesta: La lista de funciones que contiene el AST es la siguiente:\n",
      "\n",
      "1. Funci√≥n \"saludar\":\n",
      "   - Nombre: \"saludar\"\n",
      "   - Par√°metros: \"(nombre)\"\n",
      "   - Docstring: null\n",
      "   - Llamadas a otras funciones: [\"print\"]\n",
      "\n",
      "Prop√≥sito de cada funci√≥n:\n",
      "1. Funci√≥n \"saludar\": Esta funci√≥n recibe un par√°metro \"nombre\" y su prop√≥sito es imprimir un saludo utilizando el valor del par√°metro \"nombre\" mediante la funci√≥n \"print\".\n",
      "\n",
      "En cuanto a la funci√≥n \"saludar\" del JSON proporcionado, puedo decirte que:\n",
      "- La funci√≥n \"saludar\" tiene como nombre \"saludar\".\n",
      "- La funci√≥n \"saludar\" recibe un par√°metro llamado \"nombre\".\n",
      "- La funci√≥n \"saludar\" no tiene un docstring asociado.\n",
      "- La funci√≥n \"saludar\" realiza una llamada a la funci√≥n \"print\".\n",
      "Herramienta usada: busqueda_json\n",
      "----------------------------------------\n",
      "\n",
      "Respuesta: Thor (en n√≥rdico antiguo: √û√≥rr) es el dios n√≥rdico del trueno, el cielo y la agricultura. Es hijo de Od√≠n, jefe de los dioses, y de la consorte de Od√≠n, Jord (Tierra), y esposo de la diosa de la fertilidad Sif, madre de su hijo Modi y de su hija Thrud; su otro hijo, Magni, puede ser fruto de una uni√≥n con la giganta Jarnsaxa.\n",
      "\n",
      "Thor es el m√°s noble de ellos [los √Üsir], es llamado Thor de los √Üsir, u √ñku-Thor; es el m√°s fuerte de los dioses y los hombres. ... Thor quien hab√≠a sido enemigo de su abuelo y le hab√≠a dado muerte, se encarga h√°bilmente de responder con maldiciones que neutralizan todas las bendiciones que le otorga Od√≠n. Entonces Thor habl√≥: 'La\n",
      "\n",
      "Thor era uno de los dioses m√°s importantes de la mitolog√≠a n√≥rdica y, seguramente, el m√°s popular. Era muy venerado ya que, a diferencia de otros dioses, ten√≠a gran simpat√≠a por los humanos a los que proteg√≠a y ayudaba cuando estaban en problemas. Este dios se destacaba m√°s por su fuerza sobrenatural que por su astucia ya que era un poco torpe y no muy inteligente; adem√°s, sol√≠a\n",
      "Herramienta usada: busqueda_internet\n",
      "----------------------------------------\n",
      "\n",
      "Respuesta: Sin resultados\n",
      "Herramienta usada: busqueda_internet\n",
      "----------------------------------------\n",
      "\n",
      "Respuesta: Thor es un superh√©roe ficticio que aparece en los c√≥mics estadounidenses publicados por Marvel Comics. Es el dios del trueno asgardiano basado en la deidad hom√≥nima, del pueblo ficticio inspirado en el mundo de Asgard de la mitolog√≠a n√≥rdica, de donde toman inspiraci√≥n muchos aspectos del personaje.\n",
      "\n",
      "La batalla de Thor contra los gigantes, de M√•rten Eskil Winge, 1872. Thor (del n√≥rdico antiguo √û√≥rr, pronunciado / Œ∏oÀêrÀê / en island√©s antiguo y / Œ∏oÕ°uÃØrÃ• / en island√©s moderno) es el dios del trueno y fuerza en la mitolog√≠a n√≥rdica y germ√°nica. Su papel es complejo ya que ten√≠a influencia en √°reas muy diferentes, tales como el clima, las cosechas, la protecci√≥n, la\n",
      "\n",
      "Thor Odinson es el Dios del Trueno, anterior Rey de Asgard y Nuevo Asgard, un miembro fundador de los Vengadores y antiguo miembro de los Guardianes de la Galaxia. Cuando su conducta irresponsable amenaz√≥ a los Asgardianos a entrar en otra guerra con los Gigantes de Hielo, fue despojado de su poder y desterrado en la Tierra por su padre, Od√≠n. Mientras estaba exiliado, Thor aprendi√≥ sobre\n",
      "Herramienta usada: busqueda_internet\n",
      "----------------------------------------\n",
      "\n",
      "Respuesta: 1. Utiliza Flows que combinan Agentes y Copilots para mejorar el flujo de desarrollo del programador.\n",
      "2. Permite acceso al proyecto completo sin especificaciones detalladas, generando c√≥digo mientras se entiende el contexto.\n",
      "3. Integra informaci√≥n sobre problemas detectados en el c√≥digo y es compatible con linters.\n",
      "4. Consciente de las acciones en tiempo real del usuario para una experiencia m√°s din√°mica.\n",
      "5. Integra un lenguaje natural avanzado para un procesamiento avanzado.\n",
      "\n",
      "Fuentes:\n",
      "- Investigaci√≥n de WindSurf.pdf\n",
      "- Investigaci√≥n de WindSurf.pdf\n",
      "- Investigaci√≥n de WindSurf.pdf\n",
      "Herramienta usada: busqueda_pdf\n",
      "----------------------------------------\n",
      "\n",
      "Respuesta: Sin resultados\n",
      "Herramienta usada: busqueda_internet\n",
      "----------------------------------------\n",
      "\n",
      "Respuesta: Sin resultados\n",
      "Herramienta usada: busqueda_internet\n",
      "----------------------------------------\n",
      "\n",
      "Respuesta: Sin resultados\n",
      "Herramienta usada: busqueda_internet\n",
      "----------------------------------------\n",
      "\n",
      "Respuesta: 1. Utiliza Flows que combinan Agentes y Copilots para mejorar el flujo de desarrollo del programador.\n",
      "2. Permite acceso al proyecto completo sin necesidad de especificaciones detalladas.\n",
      "3. Integra informaci√≥n sobre problemas detectados en el c√≥digo y es compatible con linters.\n",
      "4. Consciente de las acciones en tiempo real del usuario, lo que permite una experiencia m√°s din√°mica.\n",
      "5. Integra un lenguaje natural avanzado para un procesamiento avanzado.\n",
      "\n",
      "Fuentes:\n",
      "- Investigaci√≥n de WindSurf.pdf\n",
      "- Investigaci√≥n de WindSurf.pdf\n",
      "- Investigaci√≥n de WindSurf.pdf\n",
      "Herramienta usada: busqueda_pdf\n",
      "----------------------------------------\n",
      "Fin de la conversaci√≥n.\n"
     ]
    }
   ],
   "source": [
    "# Celda 5: Chatbot interactivo\n",
    "print(\"Chatbot de LangGraph - escriba 'salir' para terminar.\")\n",
    "\n",
    "while True:\n",
    "    pregunta = input(\"Usuario: \")\n",
    "\n",
    "    if pregunta.lower() in [\"salir\", \"exit\", \"quit\"]:\n",
    "        print(\"Fin de la conversaci√≥n.\")\n",
    "        break\n",
    "\n",
    "    entrada_agente = {\"input\": pregunta, \"tool_used\": \"none\", \"output\": \"\"}\n",
    "    resultado = agent_executor.invoke(entrada_agente)\n",
    "\n",
    "    print(\"\\nRespuesta:\", resultado[\"output\"])\n",
    "    print(\"Herramienta usada:\", resultado[\"tool_used\"])\n",
    "    print(\"-\" * 40)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
