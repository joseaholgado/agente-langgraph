{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae7da91f",
   "metadata": {},
   "source": [
    "# Agente Inteligente con LangGraph\n",
    "Este notebook implementa un agente que decide autom√°ticamente si debe buscar en documentos PDF o hacer una b√∫squeda web para responder preguntas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c511a34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 1: Configuraci√≥n inicial\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import TypedDict\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "api_key_tavily = os.getenv(\"TAVILY_API_KEY\")\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", api_key=api_key, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bf50910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2: Clase para b√∫squeda en PDFs\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "class BusquedaPDF:\n",
    "    def __init__(self, pdf_paths):\n",
    "        docs = []\n",
    "        for path in pdf_paths:\n",
    "            loader = PyMuPDFLoader(path)\n",
    "            docs.extend(loader.load())\n",
    "\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "        docs_fragmentados = splitter.split_documents(docs)\n",
    "\n",
    "        self.embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "        self.vectorstore = FAISS.from_documents(docs_fragmentados, self.embeddings)\n",
    "\n",
    "        llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", api_key=api_key)\n",
    "        self.qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=self.vectorstore.as_retriever())\n",
    "\n",
    "    def run(self, query: str) -> str:\n",
    "        respuesta = self.qa_chain.run(query)\n",
    "        return respuesta\n",
    "\n",
    "rutas_pdfs = [\"Investigaci√≥n de WindSurf.pdf\", \"nke-10k-2023.pdf\"]\n",
    "buscador_pdf = BusquedaPDF(rutas_pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1a0a900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 3: Herramienta de b√∫squeda web\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain.tools import Tool\n",
    "\n",
    "tavily_tool = TavilySearch(max_results=5, topic=\"general\")\n",
    "\n",
    "def busqueda_internet(query: str) -> str:\n",
    "    output = tavily_tool.invoke({\"query\": query})\n",
    "    resultados = output.get(\"results\", [])\n",
    "    if not resultados:\n",
    "        return \"No se encontraron resultados relevantes en la b√∫squeda en l√≠nea.\"\n",
    "    contenido = \"\\n\\n\".join([res[\"content\"] for res in resultados[:3] if \"content\" in res])\n",
    "    return contenido\n",
    "\n",
    "tool_pdf = Tool(\n",
    "    name=\"busqueda_pdf\",\n",
    "    func=buscador_pdf.run,\n",
    "    description=\"Busca informaci√≥n en los documentos PDF cargados.\"\n",
    ")\n",
    "\n",
    "tool_web = Tool(\n",
    "    name=\"busqueda_internet\",\n",
    "    func=busqueda_internet,\n",
    "    description=\"Realiza b√∫squedas en Internet para informaci√≥n actualizada.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "be959777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 4 Modificada: Configuraci√≥n corregida de LangGraph\n",
    "from langgraph.graph import StateGraph\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    tool_used: str\n",
    "    output: str\n",
    "    next_step: str  # Nuevo campo para control de flujo\n",
    "\n",
    "def decide_tool(state: AgentState) -> AgentState:\n",
    "    pregunta = state[\"input\"]\n",
    "    prompt = [\n",
    "        SystemMessage(content=\"Eres un asistente que elige la mejor herramienta seg√∫n la consulta.\"),\n",
    "        HumanMessage(content=f'''\n",
    "Dada la siguiente pregunta: \"{pregunta}\", ¬øcu√°l herramienta deber√≠a usar?\n",
    "\n",
    "**NOTA**\n",
    "-Siempre que hables de Windsurf me tienes que leer el pdf\n",
    "\n",
    "Responde solo con el nombre exacto de la herramienta.\n",
    "''')\n",
    "    ]\n",
    "    respuesta = model(prompt).content.strip().lower()\n",
    "    # Retornamos un NUEVO ESTADO indicando el pr√≥ximo paso\n",
    "    if \"pdf\" in respuesta:\n",
    "        return {\"next_step\": \"usar_pdf\"}\n",
    "    elif \"internet\" in respuesta:\n",
    "        return {\"next_step\": \"usar_web\"}\n",
    "    else:\n",
    "        return {\"next_step\": \"fin\"}  # Siempre retornar dict\n",
    "\n",
    "def usar_pdf(state: AgentState) -> AgentState:\n",
    "    query = state[\"input\"]\n",
    "    resultado = tool_pdf.run(query)\n",
    "    return {\"input\": query, \"tool_used\": \"busqueda_pdf\", \"output\": resultado}\n",
    "\n",
    "def usar_web(state: AgentState) -> AgentState:\n",
    "    query = state[\"input\"]\n",
    "    resultado = tool_web.run(query)\n",
    "    return {\"input\": query, \"tool_used\": \"busqueda_internet\", \"output\": resultado}\n",
    "\n",
    "# Configuraci√≥n CORREGIDA del grafo\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"decision\", decide_tool)\n",
    "graph.add_node(\"usar_pdf\", usar_pdf)\n",
    "graph.add_node(\"usar_web\", usar_web)\n",
    "graph.add_node(\"fin\", lambda state: state)\n",
    "\n",
    "graph.set_entry_point(\"decision\")\n",
    "\n",
    "# Configuraci√≥n condicional corregida\n",
    "graph.add_conditional_edges(\n",
    "    \"decision\",\n",
    "    lambda state: state.get(\"next_step\", \"fin\"),  # Usamos el campo del estado\n",
    "    {\n",
    "        \"usar_pdf\": \"usar_pdf\",\n",
    "        \"usar_web\": \"usar_web\",\n",
    "        \"fin\": \"fin\"\n",
    "    }\n",
    ")\n",
    "\n",
    "graph.add_edge(\"usar_pdf\", \"fin\")\n",
    "graph.add_edge(\"usar_web\", \"fin\")\n",
    "\n",
    "agent_executor = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4b2699d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2 Modificada - Verificaci√≥n de PDFs\n",
    "class BusquedaPDF:\n",
    "    def __init__(self, pdf_paths):\n",
    "        try:\n",
    "            print(f\"üîç Cargando PDFs desde: {pdf_paths}\")\n",
    "            docs = []\n",
    "            for path in pdf_paths:\n",
    "                if not os.path.exists(path):\n",
    "                    raise FileNotFoundError(f\"Archivo no encontrado: {path}\")\n",
    "                loader = PyMuPDFLoader(path)\n",
    "                docs.extend(loader.load())\n",
    "                print(f\"‚úÖ {path} cargado correctamente ({len(docs)} documentos)\")\n",
    "            \n",
    "            splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "            docs_fragmentados = splitter.split_documents(docs)\n",
    "            print(f\"üìö Total fragmentos creados: {len(docs_fragmentados)}\")\n",
    "\n",
    "            self.embeddings = HuggingFaceEmbeddings(\n",
    "                model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "                model_kwargs={'device': 'cpu'}  # A√±adir par√°metro para CPU\n",
    "            )\n",
    "            \n",
    "            self.vectorstore = FAISS.from_documents(docs_fragmentados, self.embeddings)\n",
    "            print(\"ü¶Ñ Vectorstore FAISS creado exitosamente\")\n",
    "            \n",
    "            self.qa_chain = RetrievalQA.from_chain_type(\n",
    "                llm=model,\n",
    "                chain_type=\"stuff\",\n",
    "                retriever=self.vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
    "                return_source_documents=True\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error cr√≠tico al cargar PDFs: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def run(self, query: str) -> str:\n",
    "        try:\n",
    "            print(f\"\\nüîé Buscando en PDFs: '{query}'\")\n",
    "            result = self.qa_chain.invoke({\"query\": query})\n",
    "            \n",
    "            if not result[\"source_documents\"]:\n",
    "                return \"No se encontr√≥ informaci√≥n relevante en los documentos.\"\n",
    "                \n",
    "            sources = \"\\n\".join(\n",
    "                f\"- {doc.metadata['source']} (p√°gina {doc.metadata.get('page', 'N/A')})\"\n",
    "                for doc in result[\"source_documents\"]\n",
    "            )\n",
    "            \n",
    "            return f\"{result['result']}\\n\\nFuentes:\\n{sources}\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error en b√∫squeda PDF: {str(e)}\")\n",
    "            return \"Error al consultar los documentos.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1bdf4233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot de LangGraph - escriba 'salir' para terminar.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\6003465\\AppData\\Local\\Temp\\ipykernel_31288\\3478153105.py:25: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  respuesta = self.qa_chain.run(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Respuesta: Windsurf no parece ser un programa o t√©rmino t√©cnico conocido en el contexto proporcionado. Puede que se refiera a otro tipo de actividad o concepto fuera del contexto presentado. Si deseas m√°s informaci√≥n o aclaraci√≥n sobre Windsurf en otro contexto, por favor proporciona m√°s detalles.\n",
      "Herramienta usada: busqueda_pdf\n",
      "----------------------------------------\n",
      "\n",
      "Respuesta: How can I help you today?\n",
      "Herramienta usada: busqueda_pdf\n",
      "----------------------------------------\n",
      "\n",
      "Respuesta: Las caracter√≠sticas clave de Windsurf son que utiliza Flows que combinan Agentes y Copilots para mejorar el flujo de desarrollo del programador, permite acceder al proyecto completo sin necesidad de especificaciones detalladas, lo que facilita generar c√≥digo mientras se entiende el contexto. Adem√°s, Windsurf integra un lenguaje natural avanzado para un procesamiento avanzado.\n",
      "Herramienta usada: busqueda_pdf\n",
      "----------------------------------------\n",
      "\n",
      "Respuesta: J√∫piter es el planeta m√°s grande del sistema solar y el quinto en orden de lejan√≠a al Sol. [3] Es un gigante gaseoso que forma parte de los denominados planetas exteriores.Recibe su nombre del dios romano J√∫piter y los antiguos griegos le daban el nombre Fenonte. [4] Es uno de los objetos naturales m√°s brillantes en un cielo nocturno despejado, superado solo por la Luna, Venus y algunas\n",
      "\n",
      "J√∫piter es el planeta m√°s grande y el cuarto m√°s alejado del Sol. Se compone principalmente de hidr√≥geno y helio, tiene muchos sat√©lites naturales y una rotaci√≥n r√°pida.\n",
      "\n",
      "J√∫piter es el quinto planeta del sistema solar y el primero de los planetas gaseosos. Tiene el d√≠a m√°s corto, el campo magn√©tico m√°s potente y el sistema de anillos m√°s dif√≠cil de ver.\n",
      "Herramienta usada: busqueda_internet\n",
      "----------------------------------------\n",
      "Fin de la conversaci√≥n.\n"
     ]
    }
   ],
   "source": [
    "# Celda 5: Chatbot interactivo\n",
    "print(\"Chatbot de LangGraph - escriba 'salir' para terminar.\")\n",
    "\n",
    "while True:\n",
    "    pregunta = input(\"Usuario: \")\n",
    "    \n",
    "    if pregunta.lower() in [\"salir\", \"exit\", \"quit\"]:\n",
    "        print(\"Fin de la conversaci√≥n.\")\n",
    "        break\n",
    "    \n",
    "    entrada_agente = {\"input\": pregunta, \"tool_used\": \"none\", \"output\": \"\"}\n",
    "    resultado = agent_executor.invoke(entrada_agente)\n",
    "    \n",
    "    print(\"\\nRespuesta:\", resultado[\"output\"])\n",
    "    print(\"Herramienta usada:\", resultado[\"tool_used\"])\n",
    "    print(\"-\" * 40)\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
